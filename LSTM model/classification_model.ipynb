{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG0QAp_1FMjL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# # Mount Google Drive\n",
        "# drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "id": "dgcG-qVYFapD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/UNSW_NB15_training-set.csv')"
      ],
      "metadata": {
        "id": "naARnSeRFdJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yJIcld_fqo_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Tm-4PzfgFe1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674adea9-2834-44be-fcd7-cdb1cf872fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 82332 entries, 0 to 82331\n",
            "Data columns (total 18 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   id               82332 non-null  int64  \n",
            " 1   dur              82332 non-null  float64\n",
            " 2   proto            82332 non-null  object \n",
            " 3   service          82332 non-null  object \n",
            " 4   spkts            82332 non-null  int64  \n",
            " 5   dpkts            82332 non-null  int64  \n",
            " 6   sbytes           82332 non-null  int64  \n",
            " 7   dbytes           82332 non-null  int64  \n",
            " 8   sinpkt           82332 non-null  float64\n",
            " 9   dinpkt           82332 non-null  float64\n",
            " 10  tcprtt           82332 non-null  float64\n",
            " 11  synack           82332 non-null  float64\n",
            " 12  ackdat           82332 non-null  float64\n",
            " 13  smean            82332 non-null  int64  \n",
            " 14  dmean            82332 non-null  int64  \n",
            " 15  is_sm_ips_ports  82332 non-null  int64  \n",
            " 16  attack_cat       82332 non-null  object \n",
            " 17  label            82332 non-null  int64  \n",
            "dtypes: float64(6), int64(9), object(3)\n",
            "memory usage: 11.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.attack_cat.value_counts()\n",
        "df.label.value_counts()"
      ],
      "metadata": {
        "id": "KSgqkVZxFhm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fe91bb-d6fd-4da7-e7e7-45bec47e8ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    45332\n",
              "0    37000\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "#numerical_columns = ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'sinpkt', 'dinpkt', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'is_sm_ips_ports', 'label']  # List your numerical column names here\n",
        "#label_columns = ['proto', 'service', 'attack_cat']\n",
        "\n",
        "#numerical columns (scaling)\n",
        "#scaler = StandardScaler()\n",
        "#df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "#label columns (encoding)\n",
        "#label_encoders = {}\n",
        "#for col in label_columns:\n",
        "#    label_encoders[col] = LabelEncoder()\n",
        "#    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "\n",
        "\n",
        "#numerical_data = torch.tensor(df[numerical_columns].values, dtype=torch.float32)\n",
        "\n",
        "#label_tensors = [torch.tensor(df[col].values, dtype=torch.long) for col in label_columns]\n",
        "\n",
        "#labels_combined = torch.cat(label_tensors, dim=0)\n",
        "#labels_combined = labels_combined.view(-1, 3)\n",
        "\n",
        "#dataset = TensorDataset(numerical_data, labels_combined)\n",
        "df['label']\n"
      ],
      "metadata": {
        "id": "3Fexf4t3Flvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f33484-ea5b-4a20-8623-28530e064957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "82327    0\n",
              "82328    0\n",
              "82329    0\n",
              "82330    0\n",
              "82331    0\n",
              "Name: label, Length: 82332, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "numerical_columns = ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'sinpkt', 'dinpkt',  'smean', 'dmean']  # List your numerical column names here\n",
        "label_columns = ['proto','attack_cat']\n",
        "\n",
        "#numerical columns (scaling)\n",
        "scaler = StandardScaler()\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "protocol_mapping = {'tcp': 1, 'udp': 2, 'icmp': 3 , 'ospf' : 4}\n",
        "df['proto'] = df['proto'].map(protocol_mapping)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['attack_cat'] = label_encoder.fit_transform(df['attack_cat'])\n",
        "\n",
        "x=['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'sinpkt', 'dinpkt', 'smean', 'dmean','proto']\n",
        "y=['label']\n",
        "print(df['label'])\n",
        "#X_value=df[x]\n",
        "#Y_value=df[y]\n",
        "\n",
        "#print(df[numerical_columns])\n",
        "#print(df[label_columns])\n",
        "#print(df[numerical_columns].dtypes)\n",
        "\n",
        "#X_data = torch.tensor(X_value.values, dtype=torch.float32)\n",
        "\n",
        "#Y_data= torch.tensor(Y_value.values, dtype=torch.long)\n",
        "#Y_data=Y_data.view(-1,1)\n",
        "\n",
        "#X_data.shape\n",
        "#Y_data.shape\n",
        "#Y_data.shape\n",
        "#labels_combined = torch.cat(label_tensors, dim=0)\n",
        "#labels_combined = labels_combined.view(-1, 3)"
      ],
      "metadata": {
        "id": "o5kmaXJFFnkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d8c3b9-88b3-4f5b-92a6-689771317d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        0\n",
            "4        0\n",
            "        ..\n",
            "82327    0\n",
            "82328    0\n",
            "82329    0\n",
            "82330    0\n",
            "82331    0\n",
            "Name: label, Length: 82332, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['proto']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz7N5NZJwb3m",
        "outputId": "bf6bf320-67f2-4637-d087-c3227e694c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        2.0\n",
              "1        2.0\n",
              "2        2.0\n",
              "3        2.0\n",
              "4        2.0\n",
              "        ... \n",
              "82327    2.0\n",
              "82328    1.0\n",
              "82329    NaN\n",
              "82330    NaN\n",
              "82331    2.0\n",
              "Name: proto, Length: 82332, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['proto'].fillna(0, inplace=True)\n",
        "numerical_data = torch.tensor(df[x].values, dtype=torch.float32)\n",
        "label_tensors = torch.tensor(df[y].values, dtype=torch.long)\n",
        "\n",
        "#labels_combined = torch.cat(label_tensors, dim=0)\n",
        "#labels_combined = labels_combined.view(-1, 3)\n",
        "\n",
        "datasett = TensorDataset(numerical_data, label_tensors)"
      ],
      "metadata": {
        "id": "Hdu1ppLvFqNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_tensors)"
      ],
      "metadata": {
        "id": "bTLqMQb0Frqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8877aa83-4aee-4b19-986d-98c44405d628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0],\n",
            "        [0],\n",
            "        [0],\n",
            "        ...,\n",
            "        [0],\n",
            "        [0],\n",
            "        [0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(numerical_data.shape)\n",
        "print(label_tensors.shape)\n"
      ],
      "metadata": {
        "id": "xxqBPCVOFt8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0976b879-d315-4005-f305-1b0ee8093f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([82332, 10])\n",
            "torch.Size([82332, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "e1ld7KTrFwSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Assuming you already have your data loaded into numerical_data and label_tensors\n",
        "\n",
        "# Creating a dataset\n",
        "dataset = TensorDataset(numerical_data, label_tensors)\n",
        "\n",
        "# Define batch size and split sizes\n",
        "batch_size = 64\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Splitting the dataset into train and validation sets\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Creating data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Model, criterion, and optimizer initialization\n",
        "model = LSTMClassifier(input_size=len(x), hidden_size=128, num_layers=2, num_classes=2)  # Adjust num_classes accordingly\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.002)"
      ],
      "metadata": {
        "id": "5xNIphlOHegi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for inputs, labels in train_loader:\n",
        "#     optimizer.zero_grad()\n",
        "#     inputs = inputs.unsqueeze(1)\n",
        "#     outputs = model(inputs)\n",
        "\n",
        "\n",
        "#     outputs = F.softmax(outputs, dim=1)\n",
        "\n",
        "#     print(\"Outputs:\", outputs)\n",
        "#     print(\"Labels:\", labels)\n",
        "#     #  Calculating accuracy of the model\n",
        "\n",
        "#     _, predicted = torch.max(outputs, 1)  # Get the index of the maximum value\n",
        "#     correct = (predicted == labels).sum().item()  # Count correct predictions\n",
        "#     total = labels.size(0)  # Get the total number of labels\n",
        "#     accuracy = correct / total\n",
        "\n",
        "\n",
        "#     print(\"Outputs:\", outputs)\n",
        "#     print(\"Labels:\", labels)\n",
        "#     print(\"Accuracy:\", accuracy)\n",
        "\n",
        "#     labels = labels.float()  # Convert labels to float for loss calculation (if needed)\n",
        "\n",
        "#     loss = criterion(outputs, labels)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    #labels = labels.float()\n",
        "\n",
        "\n",
        "\n",
        "    #loss = criterion(outputs, labels)\n",
        "\n",
        "    #loss.backward()\n",
        "    #optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "0ZipOvAlFy1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kkumg-VIGkcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BURRRR"
      ],
      "metadata": {
        "id": "dkooFY1VJF-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "# Define the Focal Loss class\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = F.cross_entropy(input, target, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            focal_loss = self.alpha * focal_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "# Mount Google Drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('/content/UNSW_NB15_training-set.csv')\n",
        "\n",
        "# Define numerical and label columns\n",
        "numerical_columns = ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'sinpkt', 'dinpkt',  'smean', 'dmean']\n",
        "label_columns = ['proto']\n",
        "\n",
        "# Scaling numerical columns\n",
        "scaler = StandardScaler()\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "protocol_mapping = {'tcp': 1, 'udp': 2, 'icmp': 3 , 'ospf' : 4}  # Add or modify as needed\n",
        "df['proto'] = df['proto'].map(protocol_mapping)\n",
        "df['proto'] = df['proto'].map(protocol_mapping.get).fillna(0)\n",
        "\n",
        "\n",
        "# Define feature columns and target column\n",
        "x=['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'sinpkt', 'dinpkt', 'smean', 'dmean','proto']\n",
        "y = ['label']\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "numerical_data = torch.tensor(df[x].values, dtype=torch.float32)\n",
        "label_tensors = torch.tensor(df[y].values, dtype=torch.long)\n",
        "\n",
        "# Create dataset\n",
        "dataset = TensorDataset(numerical_data, label_tensors)\n",
        "\n",
        "# Define batch size and split sizes\n",
        "batch_size = 64\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Split dataset into train and validation sets\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the LSTMClassifier class\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "\n",
        "model = LSTMClassifier(input_size=len(x), hidden_size=128, num_layers=2, num_classes=2)  # Assuming 2 classes for binary classification\n",
        "criterion = FocalLoss(gamma=1.998, alpha=None, reduction='mean')  # Focal Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.008)\n"
      ],
      "metadata": {
        "id": "pDIsCcnWJEwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inside the training loop\n",
        "for inputs, labels in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    inputs = inputs.unsqueeze(1)\n",
        "    outputs = model(inputs)\n",
        "    outputs = F.softmax(outputs, dim=1)\n",
        "    labels = labels.squeeze(1)\n",
        "\n",
        "\n",
        "    # Calculating loss\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    accuracy_percent = accuracy * 100\n",
        "\n",
        "\n",
        "    print(\"Loss:\", loss.item())\n",
        "    print(\"Accuracy:\", accuracy_percent,\"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84LY5lHXJUrH",
        "outputId": "4bb19d03-e816-4f1b-dc23-58e5efeb31ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.17396049201488495\n",
            "Accuracy: 48.4375 %\n",
            "Loss: 0.17264948785305023\n",
            "Accuracy: 45.3125 %\n",
            "Loss: 0.1717144250869751\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.17001451551914215\n",
            "Accuracy: 57.8125 %\n",
            "Loss: 0.17230036854743958\n",
            "Accuracy: 50.0 %\n",
            "Loss: 0.16959044337272644\n",
            "Accuracy: 54.6875 %\n",
            "Loss: 0.17066064476966858\n",
            "Accuracy: 57.8125 %\n",
            "Loss: 0.1695585697889328\n",
            "Accuracy: 56.25 %\n",
            "Loss: 0.15595687925815582\n",
            "Accuracy: 65.625 %\n",
            "Loss: 0.16504546999931335\n",
            "Accuracy: 62.5 %\n",
            "Loss: 0.14606255292892456\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.16048751771450043\n",
            "Accuracy: 60.9375 %\n",
            "Loss: 0.1499737799167633\n",
            "Accuracy: 67.1875 %\n",
            "Loss: 0.1317742019891739\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.18374879658222198\n",
            "Accuracy: 60.9375 %\n",
            "Loss: 0.15861907601356506\n",
            "Accuracy: 62.5 %\n",
            "Loss: 0.15071390569210052\n",
            "Accuracy: 67.1875 %\n",
            "Loss: 0.14340749382972717\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.15790127217769623\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.13410894572734833\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.15804798901081085\n",
            "Accuracy: 67.1875 %\n",
            "Loss: 0.14526857435703278\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.12894965708255768\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.16507767140865326\n",
            "Accuracy: 56.25 %\n",
            "Loss: 0.1506601870059967\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.14815671741962433\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.15126818418502808\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.15540049970149994\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.14035458862781525\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.13515715301036835\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12668080627918243\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.13914115726947784\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.12630772590637207\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.15746507048606873\n",
            "Accuracy: 65.625 %\n",
            "Loss: 0.1571802794933319\n",
            "Accuracy: 64.0625 %\n",
            "Loss: 0.12320847809314728\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.11671045422554016\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.1517922729253769\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.13689428567886353\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.0958763062953949\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10775953531265259\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.14618569612503052\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.12900912761688232\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.15508712828159332\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.1454838067293167\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.13589470088481903\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.13324369490146637\n",
            "Accuracy: 65.625 %\n",
            "Loss: 0.16962386667728424\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.1638156622648239\n",
            "Accuracy: 64.0625 %\n",
            "Loss: 0.11429347097873688\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.13059885799884796\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.13381275534629822\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1154521107673645\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1469661444425583\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1283482015132904\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.12404336035251617\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.15357455611228943\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.13162457942962646\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.14730456471443176\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1458044946193695\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.12247306853532791\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1291520893573761\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.13503362238407135\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11352156102657318\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11299211531877518\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1418260782957077\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.14313428103923798\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.12705624103546143\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.13227608799934387\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10686242580413818\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.1329190731048584\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.16022120416164398\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.12524472177028656\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1615026295185089\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.12347080558538437\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11455902457237244\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10989737510681152\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11907248198986053\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.1315939873456955\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.12579649686813354\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1269984096288681\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10447905957698822\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1138472631573677\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.13268443942070007\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1420297920703888\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.1328292042016983\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.15301144123077393\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.12669886648654938\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.14323383569717407\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.1306287795305252\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1389777660369873\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.10832724720239639\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.1355856955051422\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.13637244701385498\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1195310652256012\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.16259010136127472\n",
            "Accuracy: 65.625 %\n",
            "Loss: 0.16120858490467072\n",
            "Accuracy: 67.1875 %\n",
            "Loss: 0.1543380171060562\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.10384245216846466\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11027473211288452\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1657828390598297\n",
            "Accuracy: 67.1875 %\n",
            "Loss: 0.1315881609916687\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.1059560775756836\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.10986356437206268\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10748794674873352\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12054779380559921\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.13430529832839966\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.10685484111309052\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.13570313155651093\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.09368618577718735\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.11434794962406158\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.12702420353889465\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1083497628569603\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1208973228931427\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.13446785509586334\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.12429340183734894\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.1467815786600113\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.07333841174840927\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.12344097346067429\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.1303606480360031\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12796518206596375\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.1028050035238266\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.12939773499965668\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11281925439834595\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.12639661133289337\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.0950993001461029\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11506867408752441\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10213617980480194\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1184774711728096\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1150747612118721\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11847154796123505\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.11122089624404907\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.12131941318511963\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.11331838369369507\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1349872201681137\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.09088005125522614\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.12487110495567322\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.11300411820411682\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.09553438425064087\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.14671160280704498\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1158941239118576\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.15501734614372253\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1431157886981964\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10889220237731934\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.13190507888793945\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1154264286160469\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10968455672264099\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.12735040485858917\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11066277325153351\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.11606945842504501\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1414777636528015\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.1201949268579483\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10798341035842896\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11766326427459717\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.10193399339914322\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.121970534324646\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.14214372634887695\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.10152283310890198\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09539787471294403\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.12571357190608978\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.11772632598876953\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.11315563321113586\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.11459529399871826\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11359177529811859\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11553468555212021\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.09470251202583313\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.07795602083206177\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.12124554067850113\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.11479406803846359\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.13423460721969604\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08147410303354263\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.17778335511684418\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.10668616741895676\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10613895952701569\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12257076799869537\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.09454303234815598\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09774909168481827\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09006898105144501\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.12850892543792725\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.0845709815621376\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11908257752656937\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.15028390288352966\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.10030481219291687\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10511898249387741\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.1358940452337265\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.13819965720176697\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.08869512379169464\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.09771378338336945\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.12284044921398163\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1060735434293747\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.13781499862670898\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11161897331476212\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11276979744434357\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12755635380744934\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.10380819439888\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.11896790564060211\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1140441745519638\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.09781672060489655\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.12419691681861877\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10944262146949768\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.11135134845972061\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.11346149444580078\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.1260240525007248\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11234739422798157\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11356596648693085\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11936944723129272\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.11173422634601593\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10918962210416794\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.07591718435287476\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1166718602180481\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1288018375635147\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.13320034742355347\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.14083431661128998\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.13155993819236755\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.12190110236406326\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.13620077073574066\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.11709614098072052\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1114606112241745\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.11786055564880371\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09427794814109802\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09109064936637878\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11304362863302231\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.1038774773478508\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11185162514448166\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1220884621143341\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12816362082958221\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.09537719190120697\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.13430748879909515\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10666153579950333\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11895632743835449\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12680914998054504\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.15788954496383667\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.13679251074790955\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.10982421040534973\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.13096635043621063\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.10442189127206802\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.11773692071437836\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.1088353842496872\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10906326025724411\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.092221699655056\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.16217146813869476\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.09548158943653107\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11452211439609528\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09207519888877869\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10459485650062561\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11534737050533295\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10304954648017883\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.1318982094526291\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.10227729380130768\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.11062287539243698\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.10612519830465317\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.087703175842762\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.13024452328681946\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.14065738022327423\n",
            "Accuracy: 65.625 %\n",
            "Loss: 0.1134486123919487\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10618936270475388\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.12675927579402924\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.08527571707963943\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.13360080122947693\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.10683172196149826\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.11855824291706085\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.09316330403089523\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11323186755180359\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.1288672834634781\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.14929501712322235\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.09141512960195541\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11837787181138992\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11378727853298187\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.14072656631469727\n",
            "Accuracy: 67.1875 %\n",
            "Loss: 0.09475809335708618\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10633668303489685\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.1365722417831421\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.12316520512104034\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.10953082889318466\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1734504997730255\n",
            "Accuracy: 62.5 %\n",
            "Loss: 0.1217007264494896\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1237039789557457\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10811518877744675\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.12524162232875824\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.12490594387054443\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.15983086824417114\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.12269338965415955\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.09985622018575668\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10449627786874771\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11628377437591553\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12321702390909195\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10047537088394165\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1367238163948059\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.15006357431411743\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.10838841646909714\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10251869261264801\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1245546042919159\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08303123712539673\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08504488319158554\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1418885886669159\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.1333904266357422\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10947644710540771\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.11492620408535004\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.13618621230125427\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.13250097632408142\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.13591983914375305\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.13272568583488464\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1378505825996399\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.10892566293478012\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.11620748043060303\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11963848024606705\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.13052384555339813\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.14537547528743744\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.11799759417772293\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11929772049188614\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1331915259361267\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.1283385455608368\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.0881880670785904\n",
            "Accuracy: 93.75 %\n",
            "Loss: 0.11616308987140656\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1117151752114296\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10584212839603424\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1384265124797821\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.132664293050766\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.08794479817152023\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.18460652232170105\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.1252608448266983\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1101095899939537\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.1179986521601677\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.10568147897720337\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.10941573977470398\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10016614198684692\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10394732654094696\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.1461830735206604\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.10392700880765915\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11173955351114273\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.13345667719841003\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.12093421071767807\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.09466902166604996\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.1428518295288086\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.09263500571250916\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10426732897758484\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.11639460176229477\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.0808984562754631\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.13300228118896484\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.11066951602697372\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.09638148546218872\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.13560771942138672\n",
            "Accuracy: 67.1875 %\n",
            "Loss: 0.10410016775131226\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1036434918642044\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.0904773473739624\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.11770188063383102\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.14850081503391266\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.11449885368347168\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11031025648117065\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10900136083364487\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11460530012845993\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.11025328934192657\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1076798141002655\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09078752994537354\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.10020244121551514\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10542210191488266\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.09878640621900558\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.12151512503623962\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.10418665409088135\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08140174299478531\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11345119029283524\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1023547500371933\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.13351154327392578\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.088216133415699\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1216588020324707\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1488795429468155\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.10133995860815048\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.12991316616535187\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12953580915927887\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.07117846608161926\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.10676690191030502\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.12069275975227356\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.0973990336060524\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.12356796860694885\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1300930678844452\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.11074931919574738\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.08095715939998627\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.12378224730491638\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.11137926578521729\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10542064160108566\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1327241212129593\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.09983642399311066\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.14095577597618103\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.10999470204114914\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08777346462011337\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.14596623182296753\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.10223152488470078\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08506649732589722\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.08876977115869522\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.12976671755313873\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.12408901751041412\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1090078353881836\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12246985733509064\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.11540406942367554\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.1183738112449646\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1116737574338913\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1209113821387291\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12551413476467133\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11369729787111282\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.09714393317699432\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08686289191246033\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.0948081836104393\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1333153247833252\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.14878249168395996\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09088153392076492\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.09780269861221313\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09161138534545898\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11033517867326736\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10371699929237366\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.0944884642958641\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10508210211992264\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.11153172701597214\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.13039158284664154\n",
            "Accuracy: 67.1875 %\n",
            "Loss: 0.09612790495157242\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08699208498001099\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.07244162261486053\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.13887837529182434\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.09613592177629471\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09492427855730057\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.10114587843418121\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.09221669286489487\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11618699133396149\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09750011563301086\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11362354457378387\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08465629070997238\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.12685495615005493\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.09974987059831619\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12856009602546692\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12662923336029053\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.1003992035984993\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10948813706636429\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.12141737341880798\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.13760912418365479\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.1258891075849533\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.12256402522325516\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11819528043270111\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.14086157083511353\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.0898580402135849\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10739099979400635\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10867620259523392\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12582673132419586\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10261635482311249\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11688759922981262\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12065578997135162\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1118474006652832\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10169752687215805\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.13197311758995056\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11064037680625916\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1395891308784485\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11547620594501495\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.1396307647228241\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.11608465760946274\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11027020961046219\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.13834381103515625\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.12608568370342255\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.14721454679965973\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10452841222286224\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12994417548179626\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.10420447587966919\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.1262470930814743\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12846440076828003\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.09724825620651245\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1190594732761383\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.13759523630142212\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.11987878382205963\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11311522126197815\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11646248400211334\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.11219482123851776\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.1240684986114502\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.10561870038509369\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.14455267786979675\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.10596588253974915\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.07427231967449188\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11349577456712723\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.0797124132514\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.08678488433361053\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.12015533447265625\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12433130294084549\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11331284791231155\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11179575324058533\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10437184572219849\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09493537247180939\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.1108943298459053\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08534140139818192\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.0783628597855568\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.10526207089424133\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.12737692892551422\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.08138585090637207\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.09772689640522003\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.08915139734745026\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10859392583370209\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10189275443553925\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10182115435600281\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.09727223962545395\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.12044250965118408\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11888210475444794\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.12047131359577179\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10720466822385788\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1118929386138916\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.08305694907903671\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.12053131312131882\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1262703239917755\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.10693442076444626\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.12732477486133575\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.13852491974830627\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.14510555565357208\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.12435600906610489\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.12768054008483887\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.14405596256256104\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10709696263074875\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10216537117958069\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.07027339190244675\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10516312718391418\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11114631593227386\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09943275898694992\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10580052435398102\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08908683061599731\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09550433605909348\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.09300438314676285\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09236215800046921\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.10153038054704666\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.12305951118469238\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.09951159358024597\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.07578270882368088\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.11068187654018402\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10121951997280121\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.13742001354694366\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12170031666755676\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.11208662390708923\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.0959361121058464\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.10587931424379349\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.13029108941555023\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.11325979977846146\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.12665055692195892\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12195077538490295\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10943152010440826\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1646575778722763\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.1348446160554886\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.13932229578495026\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.08599816262722015\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.14234580099582672\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11553865671157837\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10350371897220612\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10744289308786392\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08834359049797058\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10233870893716812\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.090378537774086\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09011250734329224\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08094374090433121\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.1094290018081665\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.13357725739479065\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12564943730831146\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.09421408176422119\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09695503115653992\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10202538222074509\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10436200350522995\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.12439637631177902\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.07521364092826843\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.09530133008956909\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11641551554203033\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11316148936748505\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08797797560691833\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.10337567329406738\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11202763766050339\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.13516274094581604\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11450236290693283\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10312739759683609\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.08308858424425125\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.1273023635149002\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.0965961217880249\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08380463719367981\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11331550031900406\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12805305421352386\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.0806107148528099\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11922501772642136\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.08686640113592148\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1215013638138771\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10038751363754272\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09217168390750885\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.0989065170288086\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11315488070249557\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1260039210319519\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.10884813964366913\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.09870600700378418\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.08812202513217926\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.12548790872097015\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12469415366649628\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.12306399643421173\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.13904862105846405\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.07348677515983582\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.13459235429763794\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.1163664236664772\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10877647250890732\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09691858291625977\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09204211086034775\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.11989614367485046\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.13000503182411194\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.11653236299753189\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.09230691194534302\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09512466937303543\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10938750207424164\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09389664232730865\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.13930106163024902\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.13426581025123596\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.11129730939865112\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.13713394105434418\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.12189675122499466\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09398996829986572\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.10280825197696686\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.12998679280281067\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.11481811106204987\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08523391932249069\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10987959057092667\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.08848395943641663\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12914171814918518\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10872642695903778\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11979546397924423\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.12038694322109222\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.13194042444229126\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12202119827270508\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.0769948810338974\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.1131516844034195\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08963482826948166\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11895646154880524\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10316872596740723\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.12510111927986145\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.12592990696430206\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.11698316037654877\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.11230703443288803\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12469889968633652\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10638673603534698\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.1183105856180191\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.09910230338573456\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.09143418818712234\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10314352810382843\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.07572050392627716\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11220341920852661\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1099611297249794\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08585777878761292\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11384931951761246\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.11074122786521912\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.084419384598732\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09209463000297546\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11053438484668732\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.13727812469005585\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.08800183236598969\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.0987774208188057\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.08129216730594635\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.1433916687965393\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.10744377970695496\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.09499424695968628\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11918839812278748\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09020911157131195\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11138485372066498\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09650242328643799\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.09145843982696533\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10151457786560059\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08442078530788422\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.12286470830440521\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11283814162015915\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1117168590426445\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.0873403549194336\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09629956632852554\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.1039649173617363\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08721783757209778\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.08881174027919769\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.1066579595208168\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.11491801589727402\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08813077956438065\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11276830732822418\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.13495858013629913\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.08804812282323837\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.09798100590705872\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08249537646770477\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.11192372441291809\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10370101034641266\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.13196036219596863\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09150396287441254\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.08509710431098938\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.12353397905826569\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.07750193774700165\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.10640665888786316\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.07553300261497498\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11873139441013336\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1405026912689209\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.07931213825941086\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.08504951745271683\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.16023606061935425\n",
            "Accuracy: 70.3125 %\n",
            "Loss: 0.11749804764986038\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.12625159323215485\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.08584365248680115\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08230844140052795\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11264979094266891\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09383932501077652\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11776487529277802\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09825844317674637\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.07276332378387451\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.10613690316677094\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09880146384239197\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.09162382036447525\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09260806441307068\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.10259745270013809\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11259965598583221\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10772588849067688\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.08220481872558594\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10809200257062912\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.15269388258457184\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.15170052647590637\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11084319651126862\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09588059037923813\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.11392872035503387\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08319366723299026\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.11952263861894608\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.07825819402933121\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.08757898211479187\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.09418228268623352\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.10512058436870575\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.0986843928694725\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09396030753850937\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11995798349380493\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11145877093076706\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11481817066669464\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.13420085608959198\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11943167448043823\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10412311553955078\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.13297155499458313\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.06776677072048187\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09907694905996323\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11854435503482819\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.08722829818725586\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10040847957134247\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08929461240768433\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.13245715200901031\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.0776277482509613\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.08902885019779205\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.09115882962942123\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.13426722586154938\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.07182112336158752\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.07147766649723053\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.11247387528419495\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10397110879421234\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1221407875418663\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09345711022615433\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.15354757010936737\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.08823844790458679\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.0875139832496643\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11501391232013702\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10909465700387955\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.09344612061977386\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11652253568172455\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10730910301208496\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09926524758338928\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10074177384376526\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10495240986347198\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.101297527551651\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.07337048649787903\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10605119913816452\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.0996154323220253\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11134032160043716\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10186439752578735\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.08594104647636414\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10110166668891907\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.0871938169002533\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09793133288621902\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.07644841820001602\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.13228020071983337\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.0939158946275711\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10476208478212357\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.11002472043037415\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.14035600423812866\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.08211483806371689\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.13166111707687378\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12513509392738342\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.1054648831486702\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09118242561817169\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.06848880648612976\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.08830332010984421\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10346785932779312\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08806033432483673\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.08644689619541168\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.09080825746059418\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.0992518961429596\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.11012490093708038\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10005317628383636\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.09990209341049194\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.14451903104782104\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.1090998724102974\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09267519414424896\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11131720244884491\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10616645216941833\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.12169503420591354\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.11906526982784271\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.11621994525194168\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.1152556985616684\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10887300223112106\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08094975352287292\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.12204481661319733\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.10282396525144577\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.08310827612876892\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.09641418606042862\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10812835395336151\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08337768912315369\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.11773117631673813\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11746009439229965\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.13738808035850525\n",
            "Accuracy: 71.875 %\n",
            "Loss: 0.10318884998559952\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.07296277582645416\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.086457259953022\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.09571349620819092\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.09775309264659882\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.0783173218369484\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.10472803562879562\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.13120323419570923\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.11017151176929474\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.09913621842861176\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10711326450109482\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11562991142272949\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09196636080741882\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09434811770915985\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09185174107551575\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.0906510278582573\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09160321205854416\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.100392647087574\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10055595636367798\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.09619247913360596\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10905253142118454\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09584886580705643\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.14862246811389923\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.06295618414878845\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.10150513052940369\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11344637721776962\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09917139261960983\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10782255232334137\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.13076722621917725\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.11350933462381363\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11489961296319962\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.11015070229768753\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.09800317138433456\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10243396461009979\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09202791005373001\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10950826108455658\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09901803731918335\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10052988678216934\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08644494414329529\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.0916619673371315\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.1375149041414261\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.09908140450716019\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.07498112320899963\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.09149627387523651\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.12084954231977463\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10246037691831589\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.0974942296743393\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1129622608423233\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08184021711349487\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09161308407783508\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08928032219409943\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.07848232984542847\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.09887149184942245\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.10479041188955307\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.13428995013237\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.07440964877605438\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.1038031131029129\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.0885530635714531\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09501051902770996\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10292129963636398\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10848406702280045\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08514181524515152\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.09955066442489624\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.07302071154117584\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.0749778002500534\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.08915601670742035\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.12409147620201111\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10733463615179062\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09515958279371262\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.06966518610715866\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.12021021544933319\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.10285042226314545\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.13274435698986053\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.061825498938560486\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.08375057578086853\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.1368541270494461\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.13447245955467224\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.0915851965546608\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.0903078019618988\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.09283331036567688\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09847862273454666\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.10258927196264267\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.09497086703777313\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09060870856046677\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.07509823888540268\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.1009666919708252\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.08367529511451721\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.09364548325538635\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11351809650659561\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.10032480955123901\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.11156176775693893\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.08154462277889252\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09976840019226074\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.09264464676380157\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.13033223152160645\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10640771687030792\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.12986335158348083\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.14034539461135864\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.08560077100992203\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.08499681204557419\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.10388755798339844\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09392162412405014\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08395214378833771\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.1443147212266922\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.09836740791797638\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10389116406440735\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.12782122194766998\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11498256027698517\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.08142898231744766\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10667645931243896\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10505102574825287\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08686601370573044\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11306309700012207\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09984388947486877\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.14154894649982452\n",
            "Accuracy: 68.75 %\n",
            "Loss: 0.10890773683786392\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1150343120098114\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10687042772769928\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11359024792909622\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.07514230161905289\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.09309230744838715\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.08991454541683197\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.08666583150625229\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.09192436188459396\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09143402427434921\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09011738002300262\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.07938188314437866\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.06760194897651672\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.107109934091568\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.0852975845336914\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.09612863510847092\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.08632552623748779\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.11405572295188904\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.09121600538492203\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09608897566795349\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09826147556304932\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.12193125486373901\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10603635013103485\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.13214011490345\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.08078392595052719\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.10743192583322525\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10550783574581146\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.11971333622932434\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.08446520566940308\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.09525575488805771\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.12169637531042099\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.07735422253608704\n",
            "Accuracy: 92.1875 %\n",
            "Loss: 0.06793287396430969\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.10429621487855911\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.07864558696746826\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.12633870542049408\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08075002580881119\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.14829334616661072\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.0832035094499588\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.09561865031719208\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.09324175864458084\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09507444500923157\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.12521347403526306\n",
            "Accuracy: 73.4375 %\n",
            "Loss: 0.09230660647153854\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.12554007768630981\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.08935165405273438\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.08542607724666595\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.08690184354782104\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.11448439210653305\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10680356621742249\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.10591013729572296\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.11790996044874191\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.078901007771492\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.07325413078069687\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.09003034979104996\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.11050774157047272\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.08613410592079163\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.11141403764486313\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11738059669733047\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08844032883644104\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.10340261459350586\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08887290954589844\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09785111248493195\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.08881960064172745\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.11294068396091461\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08780286461114883\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.0936548113822937\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09983685612678528\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.08745100349187851\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08268138766288757\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.1151851937174797\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.13820615410804749\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.10289748758077621\n",
            "Accuracy: 76.5625 %\n",
            "Loss: 0.10655730962753296\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.07354982942342758\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.09331807494163513\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.0998435914516449\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.1117905005812645\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.08363159745931625\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.07422789186239243\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.10296021401882172\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.10537312924861908\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.121923066675663\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.11814343929290771\n",
            "Accuracy: 79.6875 %\n",
            "Loss: 0.07931198179721832\n",
            "Accuracy: 93.75 %\n",
            "Loss: 0.09682948142290115\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11368872970342636\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.10786513984203339\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.0827801451086998\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.0773049145936966\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.10249800235033035\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.09904268383979797\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1210523396730423\n",
            "Accuracy: 84.375 %\n",
            "Loss: 0.08122354745864868\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.094857357442379\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.09924240410327911\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.1338595449924469\n",
            "Accuracy: 75.0 %\n",
            "Loss: 0.1401120126247406\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.08596350252628326\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.11151410639286041\n",
            "Accuracy: 82.8125 %\n",
            "Loss: 0.12295863032341003\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.11932262778282166\n",
            "Accuracy: 81.25 %\n",
            "Loss: 0.08733021467924118\n",
            "Accuracy: 89.0625 %\n",
            "Loss: 0.09803120791912079\n",
            "Accuracy: 87.5 %\n",
            "Loss: 0.12216801196336746\n",
            "Accuracy: 78.125 %\n",
            "Loss: 0.07655676454305649\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.1115395799279213\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.09825621545314789\n",
            "Accuracy: 85.9375 %\n",
            "Loss: 0.07166998088359833\n",
            "Accuracy: 90.625 %\n",
            "Loss: 0.11842223256826401\n",
            "Accuracy: 77.77777777777779 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "jGjr0n55J58C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-jVIYnOELkIB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}